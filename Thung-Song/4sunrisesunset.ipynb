{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = '../Thung-Song-final/1final/'\n",
    "OUTPUT = '../Thung-Song-final-SunriseSunset/1duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT):\n",
    "    os.makedirs(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all Excel files in the target directory\n",
    "excel_files = [f for f in os.listdir(TARGET) if f.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(TARGET):\n",
    "    for filename in os.listdir(TARGET):\n",
    "        file_path = os.path.join(TARGET, filename)\n",
    "        if filename.endswith('.xlsx'):\n",
    "            print(filename)\n",
    "            df = pd.read_excel(file_path)\n",
    "            # print(df.head())\n",
    "            dataframes.append(df)\n",
    "else:\n",
    "    print(f'{TARGET} is not a directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into one\n",
    "df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in df.iterrows():\n",
    "    lat = data['latitude']\n",
    "    lon = data['longitude']\n",
    "    date = str(data['date']).replace('/', '-')\n",
    "    temp.append([lat, lon, date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_data(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.json()\n",
    "\n",
    "async def main():\n",
    "    urls = [f\"https://api.sunrisesunset.io/json?lat={lat}&lng={lon}&date_start={date}&date_end={date}\" for lat, lon, date in temp]\n",
    "    global responses\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_data(session, url) for url in urls]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [d['results'][0] for d in responses]\n",
    "df_api = pd.DataFrame.from_dict(responses)\n",
    "df_api = df_api[['date', 'sunrise', 'sunset']]\n",
    "df_api['date'] = df_api['date'].replace('-', '/', regex=True)\n",
    "df_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sunrise'] = pd.to_datetime(df_api['sunrise'])\n",
    "df['sunset'] = pd.to_datetime(df_api['sunset'])\n",
    "df['durationOfDay'] = (df['sunset'] - df['sunrise']).dt.total_seconds()/3600\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sunrise'] = df['sunrise'].dt.time\n",
    "df['sunset'] = df['sunset'].dt.time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['date', 'latitude', 'longitude', 'uvb', 'e', 'stl1', 'sp', 'tp', 'd2m', 'minTemp', 'meanTemp', 'maxTemp', 'RH', 'WS', 'sunrise', 'sunset', 'durationOfDay']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(OUTPUT, 'combined_sunrise_sunset_duration.xlsx')\n",
    "df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "TARGET = '../Thung-Song-final/1final/'\n",
    "OUTPUT = '../Thung-Song-final-SunriseSunset/1duration'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "# Collect all Excel files in the target directory\n",
    "excel_files = [f for f in os.listdir(TARGET) if f.endswith('.xlsx')]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Load and print each Excel file, appending it to the dataframes list\n",
    "if os.path.isdir(TARGET):\n",
    "    for filename in excel_files:\n",
    "        file_path = os.path.join(TARGET, filename)\n",
    "        print(f'Loading {filename}')\n",
    "        df = pd.read_excel(file_path)\n",
    "        dataframes.append(df)\n",
    "else:\n",
    "    print(f'{TARGET} is not a directory.')\n",
    "\n",
    "# Combine all dataframes into one\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Extract latitude, longitude, and date data for API requests\n",
    "temp = []\n",
    "responses = []\n",
    "\n",
    "for i, data in df.iterrows():\n",
    "    lat = data['latitude']\n",
    "    lon = data['longitude']\n",
    "    date = str(data['date']).replace('/', '-')\n",
    "    temp.append([lat, lon, date])\n",
    "\n",
    "# Asynchronous function to fetch data from the API\n",
    "async def fetch_data(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.json()\n",
    "\n",
    "# Asynchronous function to manage API requests\n",
    "async def main():\n",
    "    urls = [f\"https://api.sunrisesunset.io/json?lat={lat}&lng={lon}&date_start={date}&date_end={date}\" for lat, lon, date in temp]\n",
    "    global responses\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_data(session, url) for url in urls]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the asynchronous function\n",
    "asyncio.run(main())\n",
    "\n",
    "# Process the API responses and convert them to a dataframe\n",
    "responses = [d['results'][0] for d in responses]\n",
    "df_api = pd.DataFrame.from_dict(responses)\n",
    "df_api = df_api[['date', 'sunrise', 'sunset']]\n",
    "df_api['date'] = df_api['date'].replace('-', '/', regex=True)\n",
    "\n",
    "# Merge the API data with the original dataframe\n",
    "df['sunrise'] = pd.to_datetime(df_api['sunrise'])\n",
    "df['sunset'] = pd.to_datetime(df_api['sunset'])\n",
    "df['durationOfDay'] = (df['sunset'] - df['sunrise']).dt.total_seconds() / 3600\n",
    "\n",
    "# Convert sunrise and sunset columns to time format\n",
    "df['sunrise'] = df['sunrise'].dt.time\n",
    "df['sunset'] = df['sunset'].dt.time\n",
    "\n",
    "# Select and reorder the relevant columns\n",
    "df = df[['date', 'latitude', 'longitude', 'uvb', 'e', 'stl1', 'sp', 'tp', 'd2m', 'minTemp', 'meanTemp', 'maxTemp', 'RH', 'WS', 'sunrise', 'sunset', 'durationOfDay']]\n",
    "\n",
    "# Save the updated dataframe to a new Excel file\n",
    "output_file = os.path.join(OUTPUT, 'combined_sunrise_sunset_duration.xlsx')\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f'Saved updated dataframe to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from aiohttp import ClientSession\n",
    "from aiohttp.client_exceptions import ClientConnectorError, ClientOSError, ServerDisconnectedError\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "TARGET = '../Thung-Song-final/3final/'\n",
    "OUTPUT = '../Thung-Song-final-SunriseSunset/3duration'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "# Collect all Excel files in the target directory\n",
    "excel_files = [f for f in os.listdir(TARGET) if f.endswith('.xlsx')]\n",
    "\n",
    "# Function to process each Excel file\n",
    "async def process_file(file_path, filename):\n",
    "    print(f'Loading {filename}')\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Extract latitude, longitude, and date data for API requests\n",
    "    temp = []\n",
    "    for i, data in df.iterrows():\n",
    "        lat = data['latitude']\n",
    "        lon = data['longitude']\n",
    "        date = str(data['date']).replace('/', '-')\n",
    "        temp.append([lat, lon, date])\n",
    "\n",
    "    # Asynchronous function to fetch data from the API with retry logic\n",
    "    async def fetch_data(session, url, retries=3, backoff_factor=1.0):\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                async with session.get(url) as response:\n",
    "                    if response.status == 200:\n",
    "                        return await response.json()\n",
    "                    else:\n",
    "                        print(f\"Error response {response.status} for URL: {url}\")\n",
    "            except (ClientConnectorError, ClientOSError, ServerDisconnectedError) as e:\n",
    "                print(f\"Request failed: {e}. Retrying ({attempt + 1}/{retries})...\")\n",
    "                await asyncio.sleep(backoff_factor * (2 ** attempt))\n",
    "        print(f\"Failed to fetch data from {url} after {retries} retries.\")\n",
    "        return None\n",
    "\n",
    "    # Asynchronous function to manage API requests\n",
    "    async def fetch_all_data():\n",
    "        urls = [f\"https://api.sunrisesunset.io/json?lat={lat}&lng={lon}&date_start={date}&date_end={date}\" for lat, lon, date in temp]\n",
    "        responses = []\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [fetch_data(session, url) for url in urls]\n",
    "            responses = await asyncio.gather(*tasks)\n",
    "        return [response for response in responses if response is not None]\n",
    "\n",
    "    responses = await fetch_all_data()\n",
    "\n",
    "    if not responses:\n",
    "        print(f\"No data fetched for {filename}. Skipping file.\")\n",
    "        return\n",
    "\n",
    "    # Process the API responses and convert them to a dataframe\n",
    "    responses = [d['results'][0] for d in responses]\n",
    "    df_api = pd.DataFrame.from_dict(responses)\n",
    "    df_api = df_api[['date', 'sunrise', 'sunset']]\n",
    "    df_api['date'] = df_api['date'].replace('-', '/', regex=True)\n",
    "\n",
    "    # Merge the API data with the original dataframe\n",
    "    df['sunrise'] = pd.to_datetime(df_api['sunrise'])\n",
    "    df['sunset'] = pd.to_datetime(df_api['sunset'])\n",
    "    df['durationOfDay'] = (df['sunset'] - df['sunrise']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Convert sunrise and sunset columns to time format\n",
    "    df['sunrise'] = df['sunrise'].dt.time\n",
    "    df['sunset'] = df['sunset'].dt.time\n",
    "\n",
    "    # Select and reorder the relevant columns\n",
    "    df = df[['date', 'latitude', 'longitude', 'uvb', 'e', 'stl1', 'sp', 'tp', 'd2m', 'minTemp', 'meanTemp', 'maxTemp', 'RH', 'WS', 'sunrise', 'sunset', 'durationOfDay']]\n",
    "\n",
    "    # Save the updated dataframe to a new Excel file\n",
    "    output_file = os.path.join(OUTPUT, f'{filename.split(\".\")[0]}-durationOfDay.xlsx')\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(f'Saved updated dataframe to {output_file}')\n",
    "\n",
    "# Run the processing for each file\n",
    "async def main():\n",
    "    tasks = [process_file(os.path.join(TARGET, filename), filename) for filename in excel_files]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
